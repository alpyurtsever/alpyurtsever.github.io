<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.14.1 by Michael Rose
  Copyright 2013-2018 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>My Publications | ALP YURTSEVER</title>
<meta name="description" content="">



<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="ALP YURTSEVER">
<meta property="og:title" content="My Publications">
<meta property="og:url" content="http://localhost:4000/publications/">












  

  


<link rel="canonical" href="http://localhost:4000/publications/">







  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Person",
      "name": "Alp Yurtsever",
      "url": "http://localhost:4000",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="ALP YURTSEVER Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--archive">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <!-- <a class="site-title" href="/">ALP YURTSEVER</a>n-->
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/curriculum/" >CURRICULUM</a>
            </li><li class="masthead__menu-item">
              <a href="/publications/" >PUBLICATIONS</a>
            </li><li class="masthead__menu-item">
              <a href="/talks/" >TALKS</a>
            </li><li class="masthead__menu-item">
              <a href="/software/" >SOFTWARE</a>
            </li><li class="masthead__menu-item">
              <a href="/" ><i class="fas fa-home"></i></a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      

      
        <img src="/assets/images/alp-avatar.jpg" alt="Alp Yurtsever" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Alp Yurtsever</h3>
    
    
      <p class="author__bio" itemprop="description">
        I am a PhD student at <a href=https://www.epfl.ch/en/home>EPFL</a>, advised by <a href=https://people.epfl.ch/volkan.cevher/bio?lang=en&cvlang=en>Prof. Volkan Cevher</a>. <br> My research interests involve optimization and machine learning.
      </p>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">EPFL STI IEL LIONS <br> ELD 244 Station 11 <br> 1015 Lausanne, Switzerland</span>
        </li>
      

      
        
          
            <li><a href="" rel="nofollow noopener noreferrer"><i class="fas fa-envelope" aria-hidden="true"></i> alp.yurtsever *at* epfl.ch</a></li>
          
        
          
            <li><a href="" rel="nofollow noopener noreferrer"><i class="fas fa-phone" aria-hidden="true"></i> +41 21 69 31154</a></li>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <div class="archive">
    
      <h1 id="page-title" class="page__title">My Publications</h1>
    
    <head>
<title>JabRef references</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<script type="text/javascript">
<!--
// QuickSearch script for JabRef HTML export 
// Version: 3.0
//
// Copyright (c) 2006-2011, Mark Schenk
//
// This software is distributed under a Creative Commons Attribution 3.0 License
// http://creativecommons.org/licenses/by/3.0/
//
// Features:
// - intuitive find-as-you-type searching
//    ~ case insensitive
//    ~ ignore diacritics (optional)
//
// - search with/without Regular Expressions
// - match BibTeX key
//

function loadTableData() {
	// find table and appropriate rows
	searchTable = document.getElementById('qs_table');
	var allRows = searchTable.getElementsByTagName('tbody')[0].getElementsByTagName('tr');

	// split all rows into entryRows and infoRows (e.g. abstract, review, bibtex)
	entryRows = new Array(); infoRows = new Array(); absRows = new Array(); revRows = new Array();

	// get data from each row
	entryRowsData = new Array(); absRowsData = new Array(); revRowsData = new Array(); 
	
	BibTeXKeys = new Array();
	
	for (var i=0, k=0, j=0; i<allRows.length;i++) {
		if (allRows[i].className.match(/entry/)) {
			entryRows[j] = allRows[i];
			entryRowsData[j] = stripDiacritics(getTextContent(allRows[i]));
			allRows[i].id ? BibTeXKeys[j] = allRows[i].id : allRows[i].id = 'autokey_'+j;
			j ++;
		} else {
			infoRows[k++] = allRows[i];
			// check for abstract/review
			if (allRows[i].className.match(/abstract/)) {
				absRows.push(allRows[i]);
				absRowsData[j-1] = stripDiacritics(getTextContent(allRows[i]));
			} else if (allRows[i].className.match(/review/)) {
				revRows.push(allRows[i]);
				revRowsData[j-1] = stripDiacritics(getTextContent(allRows[i]));
			}
		}
	}
	//number of entries and rows
	numEntries = entryRows.length;
	numInfo = infoRows.length;
	numAbs = absRows.length;
	numRev = revRows.length;
}


// Strip Diacritics from text
// http://stackoverflow.com/questions/990904/javascript-remove-accents-in-strings

// String containing replacement characters for stripping accents 
var stripstring = 
    'AAAAAAACEEEEIIII'+
    'DNOOOOO.OUUUUY..'+
    'aaaaaaaceeeeiiii'+
    'dnooooo.ouuuuy.y'+
    'AaAaAaCcCcCcCcDd'+
    'DdEeEeEeEeEeGgGg'+
    'GgGgHhHhIiIiIiIi'+
    'IiIiJjKkkLlLlLlL'+
    'lJlNnNnNnnNnOoOo'+
    'OoOoRrRrRrSsSsSs'+
    'SsTtTtTtUuUuUuUu'+
    'UuUuWwYyYZzZzZz.';

function stripDiacritics(str){

    if(noSquiggles==false){
        return str;
    }

    var answer='';
    for(var i=0;i<str.length;i++){
        var ch=str[i];
        var chindex=ch.charCodeAt(0)-192;   // Index of character code in the strip string
        if(chindex>=0 && chindex<stripstring.length){
            // Character is within our table, so we can strip the accent...
            var outch=stripstring.charAt(chindex);
            // ...unless it was shown as a '.'
            if(outch!='.')ch=outch;
        }
        answer+=ch;
    }
    return answer;
}

// http://stackoverflow.com/questions/3446170/escape-string-for-use-in-javascript-regex
// NOTE: must escape every \ in the export code because of the JabRef Export...
function escapeRegExp(str) {
  return str.replace(/[-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&");
}

function toggleInfo(articleid,info) {

	var entry = document.getElementById(articleid);
	var abs = document.getElementById('abs_'+articleid);
	var rev = document.getElementById('rev_'+articleid);
	var bib = document.getElementById('bib_'+articleid);
	
	if (abs && info == 'abstract') {
		abs.className.indexOf('noshow') == -1?abs.className = 'abstract noshow':abs.className = 'abstract show';
	} else if (rev && info == 'review') {
		rev.className.indexOf('noshow') == -1?rev.className = 'review noshow':rev.className = 'review show';
	} else if (bib && info == 'bibtex') {
		bib.className.indexOf('noshow') == -1?bib.className = 'bibtex noshow':bib.className = 'bibtex show';
	} else { 
		return;
	}

	// check if one or the other is available
	var revshow; var absshow; var bibshow;
	(abs && abs.className.indexOf('noshow') == -1)? absshow = true: absshow = false;
	(rev && rev.className.indexOf('noshow') == -1)? revshow = true: revshow = false;	
	(bib && bib.className.indexOf('noshow') == -1)? bibshow = true: bibshow = false;
	
	// highlight original entry
	if(entry) {
		if (revshow || absshow || bibshow) {
		entry.className = 'entry highlight show';
		} else {
		entry.className = 'entry show';
		}
	}
	
	// When there's a combination of abstract/review/bibtex showing, need to add class for correct styling
	if(absshow) {
		(revshow||bibshow)?abs.className = 'abstract nextshow':abs.className = 'abstract';
	} 
	if (revshow) {
		bibshow?rev.className = 'review nextshow': rev.className = 'review';
	}	
	
}

function setStatistics (hits) {
	if(hits < 0) { hits=numEntries; }
	if(stats) { stats.firstChild.data = hits + '/' + numEntries}
}

function getTextContent(node) {
	// Function written by Arve Bersvendsen
	// http://www.virtuelvis.com
	
	if (node.nodeType == 3) {
	return node.nodeValue;
	} // text node
	if (node.nodeType == 1 && node.className != "infolinks") { // element node
	var text = [];
	for (var chld = node.firstChild;chld;chld=chld.nextSibling) {
		text.push(getTextContent(chld));
	}
	return text.join("");
	} return ""; // some other node, won't contain text nodes.
}

function showAll(){
	closeAllInfo();
	for (var i = 0; i < numEntries; i++){ entryRows[i].className = 'entry show'; }
}

function closeAllInfo(){
	for (var i=0; i < numInfo; i++){
		if (infoRows[i].className.indexOf('noshow') ==-1) {
			infoRows[i].className = infoRows[i].className + ' noshow';
		}
	}
}

function clearQS() {
	qsfield.value = '';
	showAll();
}

function redoQS(){
	showAll();
	quickSearch(qsfield);
}


function toggleSettings(){
	var togglebutton = document.getElementById('showsettings');
	var settings = document.getElementById('settings');
	
	if(settings.className == "hidden"){
		settings.className = "show";
		togglebutton.innerText = "close settings";
		togglebutton.textContent = "close settings";
	}else{
		settings.className = "hidden";
		togglebutton.innerText = "settings...";		
		togglebutton.textContent = "settings...";
	}
}

-->
</script>
<style type="text/css">

div#settings ul {margin: 0; padding: 0; }
div#settings li {margin: 0; padding: 0 1em 0 0; display: inline; list-style: none; }
div#settings li + li { border-left: 2px #efefef solid; padding-left: 0.5em;}
div#settings input { margin-bottom: 0px;}

div#settings.hidden {display:none;}

#showsettings { border: 1px grey solid; padding: 0 0.5em; float:right; line-height: 1.6em; text-align: right; }
#showsettings:hover { cursor: pointer; }

table { border: 1px gray none; width: 100%; empty-cells: show; border-spacing: 0em 0.1em; margin: 1em 0em; }
th, td { border: none; padding: 0.5em; vertical-align: top; text-align: justify; }

td a { color: MediumBlue; text-decoration: none; }
td a:hover  { text-decoration: underline; }

tr.noshow { display: none;}
tr.highlight td { }
tr.abstract td, tr.review td, tr.bibtex td { background-color: LightYellow; text-align: justify; border-bottom:  2px #2E2E2E solid ; border-top: 1px #2E2E2E dashed; font-size: 11px;}
tr.nextshow td { border-bottom-style: none; }

tr.bibtex pre { width: 100%; overflow: auto; white-space: pre-wrap;}
p.infolinks { margin: 0.3em 0em 0em 0em; padding: 0px; }

@media print {
	p.infolinks, #qs_settings, #quicksearch, t.bibtex { display: none !important; }
	tr { page-break-inside: avoid; }
}
</style>
</head>
<body>

<table id="qs_table" border="1">
<tbody>
<tr id="Bang2018-NonconvexAugmentedLagrangian" class="entry">
	<td>Vu, B., Alacaoglu, A., Sahin, M., Yurtsever, A. and Cevher, V. 
	(2018), 
	<i>"A First-Order Augmented Lagrangian Framework for Nonconvex Optimization with Nonlinear Constraints"</i>
	
	, In Modern Trends in Nonconvex Optimization for Machine Learning (ICML Workshop).
	
	
	
	 
	
	
	
	
	<p class="infolinks">[<a href="javascript:toggleInfo('Bang2018-NonconvexAugmentedLagrangian','abstract')">Abstract</a>]
	 
	[<a href="javascript:toggleInfo('Bang2018-NonconvexAugmentedLagrangian','bibtex')">BibTeX</a>]
	
	 [<a href="https://drive.google.com/file/d/1r0pM67WKxqeh0ojJNaAJeq_9VKOEv4C7/preview" target="_blank">PDF</a>]
	</p>
	</td>
</tr>
<tr id="abs_Bang2018-NonconvexAugmentedLagrangian" class="abstract noshow">
	<td><b>Abstract</b>: We consider a canonical nonlinear-constrained nonconvex problem with broad applications in machine learning, theoretical computer science, and signal processing. We propose a simple primal-dual splitting scheme that provably converges to a stationary point of the non-convex problem. We achieve this desideratum via an adaptive and inexact augmented Lagrangian method. The new algorithm features a slow $O(1/)$ convergence rate, which it counteracted by its cheap per-iteration complexity. We provide numerical evidence on large-scale machine learning problems, modeled typically via semidefinite relaxations.</td>
</tr>
<tr id="bib_Bang2018-NonconvexAugmentedLagrangian" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@conference{Bang2018-NonconvexAugmentedLagrangian,
  author = {Vu, B.C. and Alacaoglu, A. and Sahin, M.F. and Yurtsever, A. and Cevher, V.},
  title = {A First-Order Augmented Lagrangian Framework for Nonconvex Optimization with Nonlinear Constraints},
  booktitle = {Modern Trends in Nonconvex Optimization for Machine Learning (ICML Workshop)},
  year = {2018},
  url = {https://drive.google.com/file/d/1r0pM67WKxqeh0ojJNaAJeq_9VKOEv4C7/preview}
}
</pre></td>
</tr>
<tr id="Cevher2018-StochasticFDR" class="entry">
	<td>Cevher, V., Vu, B. and Yurtsever, A. 
	(2018), 
	<i>"Stochastic Forward Douglas-Rachford Splitting Method for Monotone Inclusions"</i>
	
	, In Large-Scale and Distributed Optimization.
	
	
	
	 
	
	
	
	 Springer International Publishing.
	<p class="infolinks">[<a href="javascript:toggleInfo('Cevher2018-StochasticFDR','abstract')">Abstract</a>]
	 
	[<a href="javascript:toggleInfo('Cevher2018-StochasticFDR','bibtex')">BibTeX</a>]
	
	
	</p>
	</td>
</tr>
<tr id="abs_Cevher2018-StochasticFDR" class="abstract noshow">
	<td><b>Abstract</b>: We propose a stochastic Forward-Douglas-Rachford Splitting framework for finding a zero point of the sum of three maximally monotone operators in real separable Hilbert space, where one of the operators is cocoercive. We characterize the rate of convergence in expectation in the case of strongly monotone operators. We provide guidance on step-size sequences that achieve this rate, even if the strong convexity parameter is unknown.</td>
</tr>
<tr id="bib_Cevher2018-StochasticFDR" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@incollection{Cevher2018-StochasticFDR,
  author = {Cevher, V. and Vu, B.C. and Yurtsever, A.},
  editor = {Giselsson, P. and Rantzer, A.},
  title = {Stochastic Forward Douglas-Rachford Splitting Method for Monotone Inclusions},
  booktitle = {Large-Scale and Distributed Optimization},
  publisher = {Springer International Publishing},
  year = {2018}
}
</pre></td>
</tr>
<tr id="Hsieh2018-NonEuclideanFactorization" class="entry">
	<td>Hsieh, Y.-P., Kao, Y.-C., Mahabadi, R.K., Yurtsever, A., Kyrillidis, A. and Cevher, V. 
	(2018), 
	<i>"A Non-Euclidean Gradient Descent Framework for Non-Convex Matrix Factorization"</i>
	, IEEE Transactions on Signal Processing.
	
	
	
	
	 
	 Vol. 22
	(66)
	, pp. 5917-5926.
	
	<p class="infolinks">[<a href="javascript:toggleInfo('Hsieh2018-NonEuclideanFactorization','abstract')">Abstract</a>]
	 
	[<a href="javascript:toggleInfo('Hsieh2018-NonEuclideanFactorization','bibtex')">BibTeX</a>]
	
	 [<a href="https://infoscience.epfl.ch/record/231191/files/matrix_fact.pdf" target="_blank">PDF</a>]
	</p>
	</td>
</tr>
<tr id="abs_Hsieh2018-NonEuclideanFactorization" class="abstract noshow">
	<td><b>Abstract</b>: We study convex optimization problems that feature low-rank matrix solutions. In such scenarios, non-convex methods offer significant advantages over convex methods due to their lower space complexity, as well as practical faster convergence. Under mild assumptions, these methods feature global convergence guarantees.<br /><br /><br />In this paper, we extend the results on this matter by following a different path. We derive a non-Euclidean optimization framework in the non-convex setting that takes nonlinear gradient steps on the factors. Our framework enables the possibility to further exploit the underlying problem structures, such as sparsity or low-rankness on the factorized domain, or better dimensional dependence of the smoothness parameters of the objectives. We prove that the non-Euclidean methods enjoy the same rigorous guarantees as their Euclidean counterparts, under appropriate assumptions. Numerical evidence with Fourier Ptychography and FastText applications, using real data, shows that our approach can enhance solution quality, as well as convergence speed over the standard non-convex approaches.</td>
</tr>
<tr id="bib_Hsieh2018-NonEuclideanFactorization" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{Hsieh2018-NonEuclideanFactorization,
  author = {Y.-P. Hsieh and Y.-C. Kao and R. K. Mahabadi and Yurtsever, A. and Kyrillidis, A. and Cevher, V.},
  title = {A Non-Euclidean Gradient Descent Framework for Non-Convex Matrix Factorization},
  journal = {IEEE Transactions on Signal Processing},
  year = {2018},
  volume = {22},
  number = {66},
  pages = {5917--5926},
  url = {https://infoscience.epfl.ch/record/231191/files/matrix_fact.pdf}
}
</pre></td>
</tr>
<tr id="Levy2018-Accelegrad" class="entry">
	<td>Levy, K., Yurtsever, A. and Cevher, V. 
	(2018), 
	<i>"Online Adaptive Methods, Universality and Acceleration"</i>
	
	, In Advances in Neural Information Processing Systems 31 (NeurIPS).
	
	
	
	 
	
	
	
	
	<p class="infolinks">[<a href="javascript:toggleInfo('Levy2018-Accelegrad','abstract')">Abstract</a>]
	 
	[<a href="javascript:toggleInfo('Levy2018-Accelegrad','bibtex')">BibTeX</a>]
	
	 [<a href="https://papers.nips.cc/paper/7885-online-adaptive-methods-universality-and-acceleration.pdf" target="_blank">PDF</a>]
	 [<a href="https://drive.google.com/file/d/1LMhZg3s-MmM5X6OnI2VFP4ZAWZJLPLOy/view" target="_blank">Poster</a>]</p>
	</td>
</tr>
<tr id="abs_Levy2018-Accelegrad" class="abstract noshow">
	<td><b>Abstract</b>: We present a novel method for convex unconstrained optimization that, without any modifications, ensures: (i) accelerated convergence rate for smooth objectives, (ii) standard convergence rate in the general (non-smooth) setting, and (iii) standard convergence rate in the stochastic optimization setting. To the best of our knowledge, this is the first method that simultaneously applies to all of the above settings. <br /><br />At the heart of our method is an adaptive learning rate rule that employs importance weights, in the spirit of adaptive online learning algorithms, combined with an update that linearly couples two sequences. An empirical examination of our method demonstrates its applicability to the above mentioned scnearios and corroborates our theoretical findings.</td>
</tr>
<tr id="bib_Levy2018-Accelegrad" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@conference{Levy2018-Accelegrad,
  author = {Levy, K.Y. and Yurtsever, A. and Cevher, V.},
  title = {Online Adaptive Methods, Universality and Acceleration},
  booktitle = {Advances in Neural Information Processing Systems 31 (NeurIPS)},
  year = {2018},
  url = {https://papers.nips.cc/paper/7885-online-adaptive-methods-universality-and-acceleration.pdf}
}
</pre></td>
</tr>
<tr id="Tropp2018-MorePracticalSketch" class="entry">
	<td>Tropp, J., Yurtsever, A., Udell, M. and Cevher, V. 
	(2018), 
	<i>"More practical sketching algorithms for low-rank matrix approximation"</i>
	
	
	
	. ACM Report 2018-01, Caltech.
	
	 
	
	
	
	
	<p class="infolinks">[<a href="javascript:toggleInfo('Tropp2018-MorePracticalSketch','abstract')">Abstract</a>]
	 
	[<a href="javascript:toggleInfo('Tropp2018-MorePracticalSketch','bibtex')">BibTeX</a>]
	
	 [<a href="http://users.cms.caltech.edu/~jtropp/reports/TYUC18-More-Practical-TR.pdf" target="_blank">PDF</a>]
	</p>
	</td>
</tr>
<tr id="abs_Tropp2018-MorePracticalSketch" class="abstract noshow">
	<td><b>Abstract</b>: This paper describes new algorithms for constructing a low-rank approximation of an input matrix from a sketch, a random low-dimensional linear image of the matrix. These algorithms come with rigorous performance guarantees. Empirically, the proposed methods achieve significantly smaller relative errors than other approaches that have appeared in the literature. For a concrete application, the paper outlines how the algorithms support on-the-fly compression of data from a direct Navier–Stokes (DNS) simulation.</td>
</tr>
<tr id="bib_Tropp2018-MorePracticalSketch" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@techreport{Tropp2018-MorePracticalSketch,
  author = {Tropp, J.A. and Yurtsever, A. and Udell, M. and Cevher, V.},
  title = {More practical sketching algorithms for low-rank matrix approximation},
  school = {ACM Report 2018-01, Caltech},
  year = {2018},
  url = {http://users.cms.caltech.edu/~jtropp/reports/TYUC18-More-Practical-TR.pdf}
}
</pre></td>
</tr>
<tr id="Yurtsever2018-HomotopyCGM" class="entry">
	<td>Yurtsever, A., Fercoq, O., Locatello, F. and Cevher, V. 
	(2018), 
	<i>"A Conditional Gradient Framework for Composite Convex Minimization with Applications to Semidefinite Programming"</i>
	
	, In Proc. 35th Int. Conf. Machine Learning (ICML).
	
	
	
	 
	
	
	
	
	<p class="infolinks">[<a href="javascript:toggleInfo('Yurtsever2018-HomotopyCGM','abstract')">Abstract</a>]
	 
	[<a href="javascript:toggleInfo('Yurtsever2018-HomotopyCGM','bibtex')">BibTeX</a>]
	
	 [<a href="http://proceedings.mlr.press/v80/yurtsever18a/yurtsever18a.pdf" target="_blank">PDF</a>]
	</p>
	</td>
</tr>
<tr id="abs_Yurtsever2018-HomotopyCGM" class="abstract noshow">
	<td><b>Abstract</b>: We propose a conditional gradient framework for a composite convex minimization template with broad applications. Our approach combines smoothing and homotopy techniques under the CGM framework, and provably achieves the optimal $O(1/k)$ convergence rate. We demonstrate that the same rate holds if the linear subproblems are solved approximately with additive or multiplicative error. In contrast with the relevant work, we are able to characterize the convergence when the non-smooth term is an indicator function. Specific applications of our framework include the non-smooth minimization, semidefinite programming, and minimization with linear inclusion constraints over a compact domain. Numerical evidence demonstrates the benefits of our framework</td>
</tr>
<tr id="bib_Yurtsever2018-HomotopyCGM" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@conference{Yurtsever2018-HomotopyCGM,
  author = {Yurtsever, A. and Fercoq, O. and Locatello, F. and Cevher, V.},
  title = {A Conditional Gradient Framework for Composite Convex Minimization with Applications to Semidefinite Programming},
  booktitle = {Proc. 35th Int. Conf. Machine Learning (ICML)},
  year = {2018},
  url = {http://proceedings.mlr.press/v80/yurtsever18a/yurtsever18a.pdf}
}
</pre></td>
</tr>
<tr id="Tropp2017-NystromSketch" class="entry">
	<td>Tropp, J., Yurtsever, A., Udell, M. and Cevher, V. 
	(2017), 
	<i>"Fixed-rank approximation of a positive-semidefinite matrix from streaming data"</i>
	
	, In Advances in Neural Information Processing Systems 31 (NeurIPS).
	
	
	
	 
	
	
	
	
	<p class="infolinks">[<a href="javascript:toggleInfo('Tropp2017-NystromSketch','abstract')">Abstract</a>]
	 
	[<a href="javascript:toggleInfo('Tropp2017-NystromSketch','bibtex')">BibTeX</a>]
	
	 [<a href="http://papers.nips.cc/paper/6722-fixed-rank-approximation-of-a-positive-semidefinite-matrix-from-streaming-data.pdf" target="_blank">PDF</a>]
	 [<a href="https://drive.google.com/file/d/1runlikLuyTjuS2IH0I3pngQKKUdxPX-g/view" target="_blank">Poster</a>]</p>
	</td>
</tr>
<tr id="abs_Tropp2017-NystromSketch" class="abstract noshow">
	<td><b>Abstract</b>: Several important applications, such as streaming PCA and semidefinite programming, involve a large-scale positive-semidefinite (psd) matrix that is presented as a sequence of linear updates. Because of storage limitations, it may only be possible to retain a sketch of the psd matrix. This paper develops a new algorithm for fixed-rank psd approximation from a sketch. The approach combines the Nyström<br />approximation with a novel mechanism for rank truncation. Theoretical analysis establishes that the proposed method can achieve any prescribed relative error in the Schatten 1-norm and that it exploits the spectral decay of the input matrix. Computer experiments show that the proposed method dominates alternative techniques for fixed-rank psd matrix approximation across a wide range of examples.</td>
</tr>
<tr id="bib_Tropp2017-NystromSketch" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@conference{Tropp2017-NystromSketch,
  author = {Tropp, J.A. and Yurtsever, A. and Udell, M. and Cevher, V.},
  title = {Fixed-rank approximation of a positive-semidefinite matrix from streaming data},
  booktitle = {Advances in Neural Information Processing Systems 31 (NeurIPS)},
  year = {2017},
  url = {http://papers.nips.cc/paper/6722-fixed-rank-approximation-of-a-positive-semidefinite-matrix-from-streaming-data.pdf}
}
</pre></td>
</tr>
<tr id="Tropp2017-PracticalSketch" class="entry">
	<td>Tropp, J., Yurtsever, A., Udell, M. and Cevher, V. 
	(2017), 
	<i>"Practical sketching algorithms for low-rank matrix approximation"</i>
	, SIAM Journal on Matrix Analysis and Applications.
	
	
	
	
	 
	 Vol. 38
	(4)
	, pp. 1454-1485.
	
	<p class="infolinks">[<a href="javascript:toggleInfo('Tropp2017-PracticalSketch','abstract')">Abstract</a>]
	 
	[<a href="javascript:toggleInfo('Tropp2017-PracticalSketch','bibtex')">BibTeX</a>]
	
	 [<a href="https://arxiv.org/pdf/1609.00048.pdf" target="_blank">PDF</a>]
	</p>
	</td>
</tr>
<tr id="abs_Tropp2017-PracticalSketch" class="abstract noshow">
	<td><b>Abstract</b>: This paper describes a suite of algorithms for constructing low-rank approximations of an input matrix from a random linear image of the matrix, called a sketch. These methods can preserve structural properties of the input matrix, such as positive-semidefiniteness, and they can produce approximations with a user-specified rank. The algorithms are simple, accurate, numerically stable, and provably correct. Moreover, each method is accompanied by an informative error bound that allows users to select parameters a priori to achieve a given approximation quality. These claims are supported by numerical experiments with real and synthetic data.</td>
</tr>
<tr id="bib_Tropp2017-PracticalSketch" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{Tropp2017-PracticalSketch,
  author = {Tropp, J.A. and Yurtsever, A. and Udell, M. and Cevher, V.},
  title = {Practical sketching algorithms for low-rank matrix approximation},
  journal = {SIAM Journal on Matrix Analysis and Applications},
  year = {2017},
  volume = {38},
  number = {4},
  pages = {1454--1485},
  url = {https://arxiv.org/pdf/1609.00048.pdf}
}
</pre></td>
</tr>
<tr id="Tropp2017-RandomizedSingleView" class="entry">
	<td>Tropp, J., Yurtsever, A., Udell, M. and Cevher, V. 
	(2017), 
	<i>"Randomized single-view algorithms for low-rank matrix approximation"</i>
	
	
	
	. ACM Report 2017-01, Caltech.
	
	 
	
	
	
	
	<p class="infolinks">[<a href="javascript:toggleInfo('Tropp2017-RandomizedSingleView','abstract')">Abstract</a>]
	 
	[<a href="javascript:toggleInfo('Tropp2017-RandomizedSingleView','bibtex')">BibTeX</a>]
	
	 [<a href="https://authors.library.caltech.edu/74347/1/ACM_TR_2017_01.pdf" target="_blank">PDF</a>]
	</p>
	</td>
</tr>
<tr id="abs_Tropp2017-RandomizedSingleView" class="abstract noshow">
	<td><b>Abstract</b>: This paper develops a suite of algorithms for constructing low-rank approximations of an input matrix from a random linear image of the matrix, called a sketch. These methods can preserve structural properties of the input matrix, such as positive-semidefiniteness, and they can produce approximations with a user-specified rank. The algorithms are simple, accurate, numerically stable, and provably correct. Moreover, each method is accompanied by an informative error bound that allows users to select parameters a priori to achieve a given approximation quality. These claims are supported by computer experiments.</td>
</tr>
<tr id="bib_Tropp2017-RandomizedSingleView" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@techreport{Tropp2017-RandomizedSingleView,
  author = {Tropp, J.A. and Yurtsever, A. and Udell, M. and Cevher, V.},
  title = {Randomized single-view algorithms for low-rank matrix approximation},
  school = {ACM Report 2017-01, Caltech},
  year = {2017},
  url = {https://authors.library.caltech.edu/74347/1/ACM_TR_2017_01.pdf}
}
</pre></td>
</tr>
<tr id="Yurtsever2016-SketchyDecision" class="entry">
	<td>Yurtsever, A., Udell, M., Tropp, J. and Cevher, V. 
	(2017), 
	<i>"Sketchy Decisions: Convex Low-Rank Matrix Optimization with Optimal Storage"</i>
	
	, In Proc. 20th Int. Conf. Artificial Intelligence and Statistics (AISTATS).
	
	
	
	 
	
	
	
	
	<p class="infolinks">[<a href="javascript:toggleInfo('Yurtsever2016-SketchyDecision','abstract')">Abstract</a>]
	 
	[<a href="javascript:toggleInfo('Yurtsever2016-SketchyDecision','bibtex')">BibTeX</a>]
	
	 [<a href="https://arxiv.org/pdf/1702.06838.pdf" target="_blank">PDF</a>]
	</p>
	</td>
</tr>
<tr id="abs_Yurtsever2016-SketchyDecision" class="abstract noshow">
	<td><b>Abstract</b>: This paper concerns a fundamental class of convex matrix optimization problems. It presents the first algorithm that uses optimal storage and provably computes a lowrank approximation of a solution. In particular, when all solutions have low rank, the algorithm converges to a solution. This algorithm, SketchyCGM, modifies a standard convex optimization scheme, the conditional gradient method, to store only a small randomized sketch of the matrix variable. After the optimization terminates, the algorithm extracts a low-rank approximation of the solution from the sketch. In contrast to nonconvex heuristics, the guarantees for SketchyCGM do not rely on statistical models for the problem data. Numerical work demonstrates the benefits of SketchyCGM over heuristics</td>
</tr>
<tr id="bib_Yurtsever2016-SketchyDecision" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@conference{Yurtsever2016-SketchyDecision,
  author = {Yurtsever, A. and Udell, M. and Tropp, J.A. and Cevher, V.},
  title = {Sketchy Decisions: Convex Low-Rank Matrix Optimization with Optimal Storage},
  booktitle = {Proc. 20th Int. Conf. Artificial Intelligence and Statistics (AISTATS)},
  year = {2017},
  url = {https://arxiv.org/pdf/1702.06838.pdf}
}
</pre></td>
</tr>
<tr id="Odor2016-PoissonPhaseRetrieval" class="entry">
	<td>Odor, G., Li, Y.-H., Yurtsever, A., Hsieh, Y.-P., Tran-Dinh, Q., El Halabi, M. and Cevher, V. 
	(2016), 
	<i>"Frank-Wolfe Works for Non-Lipschitz Continuous Gradient Objectives: Scalable Poisson Phase Retrieval"</i>
	
	, In 41st IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).
	
	
	
	 
	
	
	
	
	<p class="infolinks">[<a href="javascript:toggleInfo('Odor2016-PoissonPhaseRetrieval','abstract')">Abstract</a>]
	 
	[<a href="javascript:toggleInfo('Odor2016-PoissonPhaseRetrieval','bibtex')">BibTeX</a>]
	
	 [<a href="https://arxiv.org/pdf/1602.00724.pdf" target="_blank">PDF</a>]
	</p>
	</td>
</tr>
<tr id="abs_Odor2016-PoissonPhaseRetrieval" class="abstract noshow">
	<td><b>Abstract</b>: We study a phase retrieval problem in the Poisson noise model. Motivated by the PhaseLift approach, we approximate the maximumlikelihood estimator by solving a convex program with a nuclear norm constraint. While the Frank-Wolfe algorithm, together with the Lanczos method, can efficiently deal with nuclear norm constraints, our objective function does not have a Lipschitz continuous gradient, and hence existing convergence guarantees for the Frank-Wolfe algorithm do not apply. In this paper, we show that the Frank-Wolfe algorithm works for the Poisson phase retrieval problem, and has a<br />global convergence rate of $O(1/t)$, where t is the iteration counter. We provide rigorous theoretical guarantee and illustrating numerical results.</td>
</tr>
<tr id="bib_Odor2016-PoissonPhaseRetrieval" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@conference{Odor2016-PoissonPhaseRetrieval,
  author = {Odor, G. and Li, Y.-H. and Yurtsever, A. and Hsieh, Y.-P. and Tran-Dinh, Q. and El~Halabi, M. and Cevher, V.},
  title = {Frank-Wolfe Works for Non-Lipschitz Continuous Gradient Objectives: Scalable Poisson Phase Retrieval},
  booktitle = {41st IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year = {2016},
  url = {https://arxiv.org/pdf/1602.00724.pdf}
}
</pre></td>
</tr>
<tr id="Yurtsever2016-StochasticThreeOperator" class="entry">
	<td>Yurtsever, A., Vu, B. and Cevher, V. 
	(2016), 
	<i>"Stochastic Three-Composite Convex Minimization"</i>
	
	, In Advances in Neural Information Processing Systems 29 (NeurIPS).
	
	
	
	 
	
	
	
	
	<p class="infolinks">[<a href="javascript:toggleInfo('Yurtsever2016-StochasticThreeOperator','abstract')">Abstract</a>]
	 
	[<a href="javascript:toggleInfo('Yurtsever2016-StochasticThreeOperator','bibtex')">BibTeX</a>]
	
	 [<a href="http://papers.nips.cc/paper/6127-stochastic-three-composite-convex-minimization.pdf" target="_blank">PDF</a>]
	 [<a href="https://drive.google.com/file/d/1BjAq0ZVgxENQEErnLp7Bo2pyP1Zgoofn/view" target="_blank">Poster</a>]</p>
	</td>
</tr>
<tr id="abs_Yurtsever2016-StochasticThreeOperator" class="abstract noshow">
	<td><b>Abstract</b>: We propose a stochastic optimization method for the minimization of the sum of three convex functions, one of which has Lipschitz continuous gradient as well as restricted strong convexity. Our approach is most suitable in the setting where it is computationally advantageous to process smooth term in the decomposition with its stochastic gradient estimate and the other two functions separately with their proximal operators, such as doubly regularized empirical risk minimization problems. We prove the convergence characterization of the proposed algorithm in expectation under the standard assumptions for the stochastic gradient estimate of the smooth term. Our method operates in the primal space and can be considered as a stochastic extension of the three-operator splitting method. Numerical evidence supports the effectiveness of our method in real-world problems.</td>
</tr>
<tr id="bib_Yurtsever2016-StochasticThreeOperator" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@conference{Yurtsever2016-StochasticThreeOperator,
  author = {Yurtsever, A. and Vu, B.C. and Cevher, V.},
  title = {Stochastic Three-Composite Convex Minimization},
  booktitle = {Advances in Neural Information Processing Systems 29 (NeurIPS)},
  year = {2016},
  url = {http://papers.nips.cc/paper/6127-stochastic-three-composite-convex-minimization.pdf}
}
</pre></td>
</tr>
<tr id="Yurtsever2015-ScalablePhaseRetrieval" class="entry">
	<td>Yurtsever, A., Hsieh, Y.-P. and Cevher, V. 
	(2015), 
	<i>"Scalable Convex Methods for Phase Retrieval"</i>
	
	, In 6th IEEE Int. Workshop Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP).
	
	
	
	 
	
	
	
	
	<p class="infolinks">[<a href="javascript:toggleInfo('Yurtsever2015-ScalablePhaseRetrieval','abstract')">Abstract</a>]
	 
	[<a href="javascript:toggleInfo('Yurtsever2015-ScalablePhaseRetrieval','bibtex')">BibTeX</a>]
	
	 [<a href="https://infoscience.epfl.ch/record/212914/files/ScalableConvexMethodsForPhaseRetrieval.pdf" target="_blank">PDF</a>]
	 [<a href="https://drive.google.com/file/d/18OoZq4QqH2uvBxdJCGMbv7nmSFy29PWj/view" target="_blank">Poster</a>]</p>
	</td>
</tr>
<tr id="abs_Yurtsever2015-ScalablePhaseRetrieval" class="abstract noshow">
	<td><b>Abstract</b>: This paper describes scalable convex optimization methods for phase retrieval. The main characteristics of these methods are the cheap per-iteration complexity and the low-memory footprint. With a variant of the original PhaseLift formulation, we first illustrate how to leverage the scalable Frank-Wolfe (FW) method (also known as the conditional gradient algorithm), which requires a tuning parameter. We demonstrate that we can estimate the tuning parameter of the FW algorithm directly from the measurements, with rigorous theoretical guarantees. We then illustrate numerically that recent advances in universal primal-dual convex optimization methods offer significant scalability improvements over the FW method, by recovering full HD resolution color images from their quadratic measurements.</td>
</tr>
<tr id="bib_Yurtsever2015-ScalablePhaseRetrieval" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@conference{Yurtsever2015-ScalablePhaseRetrieval,
  author = {Yurtsever, A. and Hsieh, Y.-P. and Cevher, V.},
  title = {Scalable Convex Methods for Phase Retrieval},
  booktitle = {6th IEEE Int. Workshop Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)},
  year = {2015},
  url = {https://infoscience.epfl.ch/record/212914/files/ScalableConvexMethodsForPhaseRetrieval.pdf}
}
</pre></td>
</tr>
<tr id="Yurtsever2015-UniversalPrimalDual" class="entry">
	<td>Yurtsever, A., Tran-Dinh, Q. and Cevher, V. 
	(2015), 
	<i>"A Universal Primal-Dual Convex Optimization Framework"</i>
	
	, In Advances in Neural Information Processing Systems 28 (NeurIPS).
	
	
	
	 
	
	
	
	
	<p class="infolinks">[<a href="javascript:toggleInfo('Yurtsever2015-UniversalPrimalDual','abstract')">Abstract</a>]
	 
	[<a href="javascript:toggleInfo('Yurtsever2015-UniversalPrimalDual','bibtex')">BibTeX</a>]
	
	 [<a href="http://papers.nips.cc/paper/5826-a-universal-primal-dual-convex-optimization-framework.pdf" target="_blank">PDF</a>]
	 [<a href="https://drive.google.com/file/d/1ulLC1uSZD2NTTkUuCQSkYmOCdeClKQfb/view" target="_blank">Poster</a>]</p>
	</td>
</tr>
<tr id="abs_Yurtsever2015-UniversalPrimalDual" class="abstract noshow">
	<td><b>Abstract</b>: We propose a new primal-dual algorithmic framework for a prototypical constrained convex optimization template. The algorithmic instances of our framework are universal since they can automatically adapt to the unknown Holder continuity degree and constant within the dual formulation. They are also guaranteed to have optimal convergence rates in the objective residual and the feasibility gap for each Holder smoothness degree. In contrast to existing primal-dual algorithms, our framework avoids the proximity operator of the objective function. We instead leverage computationally cheaper, Fenchel-type operators, which are the main workhorses of the generalized conditional gradient (GCG)-type methods. In contrast to the GCG-type methods, our framework does not require the objective function to be differentiable, and can also process additional general linear inclusion constraints, while guarantees the convergence rate on the primal problem.</td>
</tr>
<tr id="bib_Yurtsever2015-UniversalPrimalDual" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@conference{Yurtsever2015-UniversalPrimalDual,
  author = {Yurtsever, A. and Tran-Dinh, Q. and Cevher, V.},
  title = {A Universal Primal-Dual Convex Optimization Framework},
  booktitle = {Advances in Neural Information Processing Systems 28 (NeurIPS)},
  year = {2015},
  url = {http://papers.nips.cc/paper/5826-a-universal-primal-dual-convex-optimization-framework.pdf}
}
</pre></td>
</tr>
</tbody>
</table>
<footer>
<small>Please find the list ordered by citation count in my <a href="https://scholar.google.com/citations?user=wa_n-xYAAAAJ&amp;hl=en" target="_blank">Google Scholar</a> page.</small>
<br />

<small>Created by <a href="http://jabref.sourceforge.net">JabRef</a> on 24/12/2018.</small>
</footer>
<!-- file generated by JabRef -->
</body>

  </div>
</div>
    </div>

    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
          <li><a href="https://twitter.com/alp_yrtsvr" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/alpyurtsever/" rel="nofollow noopener noreferrer"><i class="fab fa-linkedin" aria-hidden="true"></i> LinkedIN</a></li>
        
      
        
      
        
      
        
      
        
      
        
      
    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2019 Alp Yurtsever. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script defer src="https://use.fontawesome.com/releases/v5.5.0/js/all.js" integrity="sha384-GqVMZRt5Gn7tB9D9q7ONtcp4gtHIUEW/yG7h98J7IpE3kpi+srfFyyB/04OV6pG0" crossorigin="anonymous"></script>








  </body>
</html>
